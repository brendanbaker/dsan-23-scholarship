{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/bren/miniproject\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping file time-series-1.json: 'jobs_results' key not found\n",
      "Skipping file time-series-analysis-1.json: 'jobs_results' key not found\n"
     ]
    }
   ],
   "source": [
    "# The first step is to get the data into a usable format. \n",
    "# We have two folders, named DC and USA.  Each contains a number of JSON files\n",
    "# The goal is to read the JSON files and create a single pandas dataframe per folder\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "def format_nested(data, key, colname, valname):\n",
    "    '''\n",
    "    Special function to format the nested job highlights data\n",
    "    '''\n",
    "    # Creating a list to store the dictionaries\n",
    "    jobs_data = []\n",
    "\n",
    "    # Iterate through each job in the data\n",
    "    for job in data:\n",
    "        # Get the job_highlights for the current job\n",
    "        job_highlights = job[key]\n",
    "        \n",
    "        # Create a dictionary to store the highlights for the current job\n",
    "        job_dict = {}\n",
    "        \n",
    "        # Iterate through the job_highlights and add them to the job_dict\n",
    "        for highlight in job_highlights:\n",
    "            \n",
    "            # If title is not in the column names, skip\n",
    "            if colname not in highlight:\n",
    "                continue\n",
    "            \n",
    "            # Get the column name from the 'title' key\n",
    "            column_name = highlight[colname]\n",
    "            \n",
    "            # Get the values from the 'items' key\n",
    "            values = highlight[valname]\n",
    "            \n",
    "            # Add the values to the job_dict under the column name\n",
    "            job_dict[column_name] = values\n",
    "        \n",
    "        # Append the job_dict to the jobs_data list\n",
    "        jobs_data.append(job_dict)\n",
    "\n",
    "    # Create a DataFrame using the jobs_data list\n",
    "    df = pd.DataFrame(jobs_data)\n",
    "    \n",
    "    return(df)\n",
    "\n",
    "\n",
    "def read_json_files(path, tag):\n",
    "    json_files = [pos_json for pos_json in os.listdir(path) if pos_json.endswith('.json')] # Get all the json files in the folder\n",
    "    df = pd.DataFrame()\n",
    "    for index, js in enumerate(json_files):\n",
    "        with open(os.path.join(path, js)) as json_file:\n",
    "            json_text = json.load(json_file)\n",
    "            if 'jobs_results' in json_text:\n",
    "                temp_df = pd.DataFrame(json_text['jobs_results'])\n",
    "                temp_text = json_text['jobs_results']\n",
    "                \n",
    "                # Expand job_highlights column\n",
    "                if 'job_highlights' in temp_df:\n",
    "                    job_highlights_df = format_nested(temp_text, 'job_highlights', 'title', 'items')\n",
    "                    temp_df = pd.concat([temp_df, job_highlights_df], axis=1).drop(['job_highlights'], axis=1)\n",
    "                \n",
    "                # Expand related_links column\n",
    "                if 'related_links' in temp_df:\n",
    "                    related_links_df = pd.json_normalize(temp_df['related_links'])\n",
    "                    related_links_df.columns = ['related_link_'+str(col) for col in related_links_df.columns]\n",
    "                    temp_df = pd.concat([temp_df, related_links_df], axis=1).drop(['related_links'], axis=1)\n",
    "                \n",
    "                # Expand detected_extensions column\n",
    "                if 'detected_extensions' in temp_df:\n",
    "                    detected_extensions_df = pd.json_normalize(temp_df['detected_extensions'])\n",
    "                    detected_extensions_df.columns = ['detected_extension_'+str(col) for col in detected_extensions_df.columns]\n",
    "                    temp_df = pd.concat([temp_df, detected_extensions_df], axis=1).drop(['detected_extensions'], axis=1)\n",
    "                \n",
    "                # Strip extension from file name, then replace dashes with spaces, then remove any numbers\n",
    "                temp_df['category'] = re.sub(r'\\d+', '', re.sub(r'-', ' ', js.split('.')[0]))\n",
    "                \n",
    "                df = pd.concat([df, temp_df])\n",
    "                \n",
    "                \n",
    "                \n",
    "                # Add the tag to the dataframe\n",
    "                df['tag'] = tag\n",
    "                \n",
    "            else:\n",
    "                print(f\"Skipping file {js}: 'jobs_results' key not found\")\n",
    "    return df\n",
    "\n",
    "\n",
    "out1 = read_json_files('./data/DC/', \"DC\")\n",
    "out2 = read_json_files('./data/USA/', \"USA\")\n",
    "\n",
    "pd.concat([out1, out2]).to_csv('./data/jobs.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('anly503')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ecea5c2fbd6271d9f0f68dda8154b78d500c74328652c23bc6c80972b4fb3462"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
